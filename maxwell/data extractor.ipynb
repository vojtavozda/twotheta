{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JF image show average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import optimize, ndimage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from extra_data import open_run\n",
    "from extra_data import by_id\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import shutil as shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_data.DataCollection for 60 sources and 4025 trains>\n"
     ]
    }
   ],
   "source": [
    "propno = 2838\n",
    "home_dir = \"/home/vozdavoj/\"\n",
    "run = open_run(proposal=propno, run=134)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare folder locations with experimental run and proposal number\n",
    "## Change this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vozdavoj\n"
     ]
    }
   ],
   "source": [
    "# Create proposal directory\n",
    "#propno = \"3213\" #\"p002353\" \n",
    "propno = \"2838\"\n",
    "home_dir = \"/home/vozdavoj/\"\n",
    "prop_dir = os.path.join(home_dir,\"p\"+propno)\n",
    "if not os.path.exists(prop_dir): os.mkdir(prop_dir)\n",
    "allruns_dir = os.path.join(prop_dir,\"runs\")\n",
    "if not os.path.exists(allruns_dir): os.mkdir(allruns_dir)\n",
    "#JF3_dir = run_dir + \"/JNGFR03\"\n",
    "#JF2_dir = run_dir + \"/JNGFR02\"\n",
    "\n",
    "os.chdir(home_dir)\n",
    "\n",
    "#if not os.path.exists(JF3_dir):\n",
    "#    os.mkdir(JF3_dir)\n",
    "\n",
    "#if not os.path.exists(JF2_dir):\n",
    "#    os.mkdir(JF2_dir)\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Open run and create run folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data by JF3 signal and save\n",
    "%matplotlib inline\n",
    "\n",
    "# T = [0.02, 1.0, 0.43, 0.18]\n",
    "#runs = [45,46,47,48]       #0fs\n",
    "#runs = [50,51,52,53]       #25fs rather 25as\n",
    "#runs = [56,58,59,60]       #50fs rather 50as\n",
    "#runs = [56, 61]            # check pump/probe ratio after operators mistake\n",
    "#runs = [63,64,65,66]       #75fs\n",
    "#runs = [69,70,71,72]        #100fs\n",
    "#runs = [75,76,77,79]        #125fs\n",
    "#runs = [81,82,85,86]        #150fs\n",
    "#runs = [88,89,90,91]        #175fs\n",
    "#runs = [93,94,95,96]        #200fs\n",
    "#runs = [99,100,101,102]     #225fs\n",
    "#runs = [104,105,106,107]    #250fs\n",
    "#runs = [109,110,111,112]    #300fs\n",
    "#runs = [114,115,116,117]    #350fs\n",
    "#runs = [119,120,121,122]    #25fs\n",
    "#runs = [124,125,126,127]    #50fs\n",
    "#runs = [128,129,130,131]    #75fs\n",
    "\n",
    "runs = [134]                 #capton diffuse scattering calibration\n",
    "\n",
    "# T = [0.02, 1.0, 0.75, 0.57, 0.32, 0.1]     # transmissions  \n",
    "#runs = [135,136,137,138,139,140]    #0fs ...DONE\n",
    "#runs = [142,143,144,145,146,147]    #25fs ...DONE\n",
    "#runs = [148,149,150,151,152,153]    #50fs  ...DONE\n",
    "#runs = range(154,160,1)             #75fs  ...DONE\n",
    "#runs = range(160,166,1)             #100fs ...DONE\n",
    "#runs = range(166,172,1)             #125fs ...DONE\n",
    "#runs = range(172,178,1)             #150fs ...DONE\n",
    "#runs = range(178,184,1)             #175fs ...DONE\n",
    "#runs = range(185,191,1)             #200fs ...DONE\n",
    "#runs = range(191,197,1)             #225fs ...DONE\n",
    "#runs = range(197,203,1)             #250fs ...DONE\n",
    "#runs = range(203,209,1)             #275fs ...DONE\n",
    "#runs = range(209,215,1)              #300fs ...DONE\n",
    "#runs = range(215,218,1)              #325fs acc. crash\n",
    "#runs = range(218,224,1)              #325fs ...DONE\n",
    "#runs = range(224,230,1)              #350fs ...DONE\n",
    "#runs = range(230,236,1)              #375fs ...DONE\n",
    "#runs = range(236,242,1)              #390fs ...DONE\n",
    "#runs = [244]                         #alumina f-scan\n",
    "\n",
    "# /INSTRUMENT/HED_IA1_EPX100-2/DET/RECEIVER:daqOutput/data/image/pixels\n",
    "# /INSTRUMENT/HED_IA1_EPX100-1/DET/RECEIVER:daqOutput/data/image/pixels\n",
    "# /INSTRUMENT/HED_IA1_JF500K3/DET/JNGFR03:daqOutput/data/adc\n",
    "# /INSTRUMENT/HED_IA1_JF500K2/DET/JNGFR02:daqOutput/data/adc\n",
    "\n",
    "# PPU = run['HED_XTD6_PPU/MDL/PPU_TRIGGER','trainTrigger.sequenceStart.value'].xarray().squeeze()\n",
    "# SA2_XTD1_XGM_iTD = run['SA2_XTD1_XGM/XGM/DOOCS:output', 'data.intensityTD'].xarray().squeeze()\n",
    "# SA2_XTD1_XGM_tID = run['SA2_XTD1_XGM/XGM/DOOCS:output', 'data.trainId'].xarray().squeeze()\n",
    "\n",
    "# HED_XTD6_XGM_iTD = run['HED_XTD6_XGM/XGM/DOOCS:output', 'data.intensityTD'].xarray().squeeze()\n",
    "# HED_XTD6_XGM_tID = run['HED_XTD6_XGM/XGM/DOOCS:output', 'data.trainId'].xarray().squeeze()\n",
    "\n",
    "#runs = [135,142,148,154,160,166,172,178,185,191,197,203,209,218,224,230,236]\n",
    "#runs = runs + np.ones(len(runs), dtype = int)\n",
    "\n",
    "#runs = [18,20,21]\n",
    "\n",
    "for i in range(0, len(runs)):\n",
    "    #print(runs[i])\n",
    "    run = open_run(propno, runs[i], \"proc\")\n",
    "    print(\"Run \" + str(runs[i]) + \" contains \" + str(len(run.train_ids)) + \" train_IDs.\")\n",
    "    \n",
    "    # Array for count,train_ids, JF3 sum, SA2 XGM, HED XGM, JF2 pump, JF2 probe\n",
    "    sums = np.zeros([7, len(run.train_ids)])\n",
    "    \n",
    "    # Create run folder and subfolders\n",
    "    run_dir = allruns_dir + \"/Run\" + str(runs[i])\n",
    "    if not os.path.exists(run_dir):\n",
    "        os.mkdir(run_dir)\n",
    "    \n",
    "    JF3_dir = run_dir + \"/JNGFR03\"\n",
    "    JF2_dir = run_dir + \"/JNGFR02\"\n",
    "    \n",
    "    if not os.path.exists(JF3_dir):\n",
    "        os.mkdir(JF3_dir)\n",
    "\n",
    "    if not os.path.exists(JF2_dir):\n",
    "        os.mkdir(JF2_dir)\n",
    "       \n",
    "    \n",
    "    # Save JF3 data and identify used trains\n",
    "    print(\"Extracting JF3 XRD data ... \")\n",
    "    os.chdir(JF3_dir)\n",
    "    print(\"Saving JF3 data to:\" + os.getcwd()) \n",
    "   \n",
    "    end = len(run.train_ids)\n",
    "    start = 0\n",
    "    count = 0\n",
    "\n",
    "\n",
    "    for j in range(start, end):\n",
    "        sel = run.select_trains(j)\n",
    "        JF3 = sel['HED_IA1_JF500K3/DET/JNGFR03:daqOutput', 'data.adc'].xarray().squeeze()       \n",
    "                   \n",
    "        # optimum threshold between 500000 and 1000000\n",
    "        # put zero to get all images\n",
    "        if JF3.data.sum().__gt__(0.0):\n",
    "            count = count + 1\n",
    "            \n",
    "            f = open(\"T\"+str(run.train_ids[j])+\".dat\", \"w\")\n",
    "            JF3.data.tofile(f)\n",
    "            f.close()\n",
    "            \n",
    "            sums[0,count-1] = count\n",
    "            sums[1,count-1] = run.train_ids[j]\n",
    "            sums[2,count-1] = JF3.data.sum()           \n",
    "           \n",
    "    print(\"Extracted images: \" + str(count))\n",
    "\n",
    "    sums = sums[:,0:count]                     # cut off useless ids\n",
    "    used_ids = sums[1,:]    \n",
    "    \n",
    "    # Pulse energy data (XGM)\n",
    "    print(\"Extracting XGM data ...\")\n",
    "    for k in range(0,count):\n",
    "        SA2_XTD1_XGM_iTD = run['SA2_XTD1_XGM/XGM/DOOCS:output', 'data.intensityTD'][by_id[[int(used_ids[k])]]].xarray().squeeze()\n",
    "        HED_XTD6_XGM_iTD = run['HED_XTD6_XGM/XGM/DOOCS:output', 'data.intensityTD'][by_id[[int(used_ids[k])]]].xarray().squeeze()\n",
    "        if len(SA2_XTD1_XGM_iTD.data).__gt__(0):\n",
    "            sums[3,k] = SA2_XTD1_XGM_iTD.data[0]\n",
    "        else:\n",
    "            sums[3,k] = 0\n",
    "            \n",
    "        if len(HED_XTD6_XGM_iTD.data).__gt__(0):\n",
    "            sums[4,k] = HED_XTD6_XGM_iTD.data[0]\n",
    "        else:\n",
    "            sums[4,k] = 0\n",
    "    \n",
    "    # Save JF2 data and integrate peaks\n",
    "    print(\"Extracting JF2 spectra data ...\")\n",
    "    os.chdir(JF2_dir)\n",
    "    print(\"Saving JF2 data to:\" + os.getcwd())  \n",
    "    \n",
    "    JF2 = run['HED_IA1_JF500K2/DET/JNGFR02:daqOutput', 'data.adc'][by_id[used_ids]].xarray().squeeze()\n",
    "    for k in range(0,count):\n",
    "        \n",
    "        ## Full image\n",
    "        spectrum = JF2.data[k,:,:]\n",
    "        f_spectrum = open(\"T\"+str(int(used_ids[k]))+\".dat\", \"w\")\n",
    "        spectrum.tofile(f_spectrum)\n",
    "        f_spectrum.close()   \n",
    "        \n",
    "        ## Cropped image\n",
    "        #spectrum = np.where(JF2.data[k,:,:]>=0,JF2.data[k,:,:],0)\n",
    "        #pump = spectrum[330:460,140:250]\n",
    "        #probe = spectrum[330:460,250:335]\n",
    "        #sums[5,k] = pump.sum()\n",
    "        #sums[6,k] = probe.sum()\n",
    "                \n",
    "        #f_pump = open(\"T\"+str(int(used_ids[k]))+\"_pump.dat\", \"w\")\n",
    "        #pump.tofile(f_pump)\n",
    "        #f_pump.close()\n",
    "        \n",
    "        #f_probe = open(\"T\"+str(int(used_ids[k]))+\"_probe.dat\", \"w\")\n",
    "        #probe.tofile(f_probe)\n",
    "        #f_probe.close()\n",
    "        \n",
    "        #tif_pump = Image.fromarray(pump)\n",
    "        #tif_pump.save(\"T\"+str(int(used_ids[k]))+\"_pump.tif\")\n",
    "        #tif_probe = Image.fromarray(probe)\n",
    "        #tif_probe.save(\"T\"+str(int(used_ids[k]))+\"_probe.tif\")\n",
    "\n",
    "    # Save text data\n",
    "    os.chdir(run_dir)\n",
    "    print(\"Saving text data to: \" + os.getcwd())\n",
    "    print(\"\")\n",
    "    np.savetxt(\"Run\" + str(runs[i])+ \"_data.txt\", np.transpose(sums), delimiter = ',', header = \"Count, Train_ID, JF3.sum, SA2_XTD1_XGM [uJ], HED_XTD6_XGM [uJ], JF2.pump.sum, JF2.probe.sum\") \n",
    "    \n",
    "# Save the zip file\n",
    "os.chdir(prop_dir)\n",
    "print(\"Saving ZIP file to: \" +os.getcwd())\n",
    "\n",
    "name = \"Runs\"\n",
    "for i in range(len(runs)):\n",
    "    name = name + \"_\" + str(runs[i])\n",
    "    \n",
    "zf = zipfile.ZipFile(name + \".zip\", \"w\")\n",
    "for root, dirs, files in os.walk(allruns_dir):\n",
    "    for directory in dirs:\n",
    "        #print(directory)\n",
    "        zf.write(os.path.join(root, directory))\n",
    "    for file in files:\n",
    "        #print(file)\n",
    "        zf.write(os.path.join(root, file))\n",
    "zf.close()\n",
    "print(\"Done.\")    \n",
    "    \n",
    "# Clean-up the run_dir for next run\n",
    "print(\"Deleting files in: \" + allruns_dir)\n",
    "for root, dirs, files in os.walk(allruns_dir):\n",
    "    for file in files:      \n",
    "        if os.path.isfile(os.path.join(root, file)):\n",
    "            #print(\"Deleting file: \" + os.path.join(root, file))\n",
    "            os.remove(os.path.join(root, file)) \n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Deleting folder: \" + allruns_dir)\n",
    "shutil.rmtree(allruns_dir)\n",
    "print(\"Done.\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "# Save tif better\n",
    "#tifimage = Image.fromarray(average)\n",
    "#tifimage.save(\"Run\"+str(runs[i])+\".tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data by PPU\n",
    "#Single shot referenced data\n",
    "\n",
    "runs = [43,49,62,68,74,80,87,92,97,103,108,118,123]\n",
    "delays = [0,0,75,100,125,150,175,200,225,250,300,25,50]\n",
    "          \n",
    "for i in range(0, len(runs)):\n",
    "    #print(runs[i])\n",
    "    run = open_run(propno, runs[i], \"proc\")\n",
    "    print(\"Run \" + str(runs[i]) + \" contains \" + str(len(run.train_ids)) + \" train_IDs.\")\n",
    "    \n",
    "    # Create run folder and subfolders\n",
    "    run_dir = allruns_dir + \"/Run\" + str(runs[i])+\"_\"+str(delays[i])+\"fs\"\n",
    "    if not os.path.exists(run_dir):\n",
    "        os.mkdir(run_dir)\n",
    "    \n",
    "    JF3_dir = run_dir + \"/JNGFR03\"\n",
    "    JF2_dir = run_dir + \"/JNGFR02\"\n",
    "    \n",
    "    if not os.path.exists(JF3_dir):\n",
    "        os.mkdir(JF3_dir)\n",
    "\n",
    "    if not os.path.exists(JF2_dir):\n",
    "        os.mkdir(JF2_dir)\n",
    "   \n",
    "    #TraiIDs used\n",
    "    PPU = run['HED_XTD6_PPU/MDL/PPU_TRIGGER','trainTrigger.sequenceStart.value'].xarray().squeeze()\n",
    "    PPU = PPU + 1\n",
    "    \n",
    "    # Save JF3 data using PPU\n",
    "    print(\"Extracting JF3 XRD data ... \")\n",
    "    os.chdir(JF3_dir)\n",
    "    print(\"Saving JF3 data to:\" + os.getcwd()) \n",
    "\n",
    "    JF3_select = run['HED_IA1_JF500K3/DET/JNGFR03:daqOutput', 'data.adc'][by_id[PPU.data]]\n",
    "    \n",
    "    # Array for count,train_ids, JF3 sum, SA2 XGM, HED XGM, JF2 pump, JF2 probe\n",
    "    sums = np.zeros([7, len(JF3_select.train_ids)])\n",
    "    \n",
    "    end = len(JF3_select.train_ids)\n",
    "    start = 0\n",
    "    \n",
    "    for j in range(start, end):       \n",
    "        JF3 = JF3_select[j].xarray().squeeze()       \n",
    "\n",
    "        f = open(\"T\"+str(JF3_select.train_ids[j])+\".dat\", \"w\")\n",
    "        JF3.data.tofile(f)\n",
    "        f.close()\n",
    "\n",
    "            \n",
    "        sums[0,j] = j\n",
    "        sums[1,j] = JF3_select.train_ids[j]\n",
    "        sums[2,j] = JF3.data.sum()           \n",
    "           \n",
    "    print(\"Extracted images: \" + str(j+1))\n",
    "    \n",
    "    used_ids = sums[1,:] \n",
    "    \n",
    "    # Pulse energy data (XGM)\n",
    "    print(\"Extracting XGM data ...\")\n",
    "    for k in range(start,end):\n",
    "        SA2_XTD1_XGM_iTD = run['SA2_XTD1_XGM/XGM/DOOCS:output', 'data.intensityTD'][by_id[[int(used_ids[k])]]].xarray().squeeze()\n",
    "        HED_XTD6_XGM_iTD = run['HED_XTD6_XGM/XGM/DOOCS:output', 'data.intensityTD'][by_id[[int(used_ids[k])]]].xarray().squeeze()\n",
    "        if len(SA2_XTD1_XGM_iTD.data).__gt__(0):\n",
    "            sums[3,k] = SA2_XTD1_XGM_iTD.data[0]\n",
    "        else:\n",
    "            sums[3,k] = 0\n",
    "            \n",
    "        if len(HED_XTD6_XGM_iTD.data).__gt__(0):\n",
    "            sums[4,k] = HED_XTD6_XGM_iTD.data[0]\n",
    "        else:\n",
    "            sums[4,k] = 0\n",
    "    \n",
    "    # Save JF2 data and integrate peaks\n",
    "    print(\"Extracting JF2 spectra data ...\")\n",
    "    os.chdir(JF2_dir)\n",
    "    print(\"Saving JF2 data to:\" + os.getcwd())  \n",
    "    \n",
    "    JF2 = run['HED_IA1_JF500K2/DET/JNGFR02:daqOutput', 'data.adc'][by_id[used_ids]].xarray().squeeze()\n",
    "    for k in range(start,end):\n",
    "        \n",
    "        ## Full image\n",
    "        spectrum = JF2.data[k,:,:]\n",
    "        f_spectrum = open(\"T\"+str(int(used_ids[k]))+\".dat\", \"w\")\n",
    "        spectrum.tofile(f_spectrum)\n",
    "        f_spectrum.close()   \n",
    "        \n",
    "        ## Cropped image\n",
    "        #spectrum = np.where(JF2.data[k,:,:]>=0,JF2.data[k,:,:],0)\n",
    "        #pump = spectrum[330:460,140:250]\n",
    "        #probe = spectrum[330:460,250:335]\n",
    "        #sums[5,k] = pump.sum()\n",
    "        #sums[6,k] = probe.sum()\n",
    "                \n",
    "        #f_pump = open(\"T\"+str(int(used_ids[k]))+\"_pump.dat\", \"w\")\n",
    "        #pump.tofile(f_pump)\n",
    "        #f_pump.close()\n",
    "        \n",
    "        #f_probe = open(\"T\"+str(int(used_ids[k]))+\"_probe.dat\", \"w\")\n",
    "        #probe.tofile(f_probe)\n",
    "        #f_probe.close()\n",
    "        \n",
    "        #tif_pump = Image.fromarray(pump)\n",
    "        #tif_pump.save(\"T\"+str(int(used_ids[k]))+\"_pump.tif\")\n",
    "        #tif_probe = Image.fromarray(probe)\n",
    "        #tif_probe.save(\"T\"+str(int(used_ids[k]))+\"_probe.tif\")\n",
    "\n",
    "    # Save text data\n",
    "    os.chdir(run_dir)\n",
    "    print(\"Saving text data to: \" + os.getcwd())\n",
    "    print(\"\")\n",
    "    np.savetxt(\"Run\" + str(runs[i])+ \"_data.txt\", np.transpose(sums), delimiter = ',', header = \"Count, Train_ID, JF3.sum, SA2_XTD1_XGM [uJ], HED_XTD6_XGM [uJ], JF2.pump.sum, JF2.probe.sum\") \n",
    "    \n",
    "# Save the zip file\n",
    "os.chdir(prop_dir)\n",
    "print(\"Saving ZIP file to: \" +os.getcwd())\n",
    "\n",
    "name = \"Runs\"\n",
    "for i in range(len(runs)):\n",
    "    name = name + \"_\" + str(runs[i])\n",
    "    \n",
    "zf = zipfile.ZipFile(name + \".zip\", \"w\")\n",
    "for root, dirs, files in os.walk(allruns_dir):\n",
    "    for directory in dirs:\n",
    "        #print(directory)\n",
    "        zf.write(os.path.join(root, directory))\n",
    "    for file in files:\n",
    "        #print(file)\n",
    "        zf.write(os.path.join(root, file))\n",
    "zf.close()\n",
    "print(\"Done.\")    \n",
    "    \n",
    "# Clean-up the run_dir for next run\n",
    "print(\"Deleting files in: \" + allruns_dir)\n",
    "for root, dirs, files in os.walk(allruns_dir):\n",
    "    for file in files:      \n",
    "        if os.path.isfile(os.path.join(root, file)):\n",
    "            #print(\"Deleting file: \" + os.path.join(root, file))\n",
    "            os.remove(os.path.join(root, file)) \n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Deleting folder: \" + allruns_dir)\n",
    "shutil.rmtree(allruns_dir)\n",
    "print(\"Done.\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "df2f6189aee400ba4ae1fda2128ad9fe163115737f80d6c8a294371d50fc0fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
